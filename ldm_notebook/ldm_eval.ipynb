{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85HpwruNho98",
    "outputId": "1f081be0-5ed0-4997-e33a-0dc4dcf98995"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Jh2XfpehaJu",
    "outputId": "0b20cd74-e05c-45c0-cb25-c3a7b1e6e4ea"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/SerdarHelli/latent-diffusion_teeth_sub_repo.git\n",
    "!git clone https://github.com/CompVis/taming-transformers\n",
    "!pip install -e /content/taming-transformers\n",
    "!pip install  torchmetrics==0.6.0\n",
    "!pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n",
    "!git clone https://github.com/openai/CLIP\n",
    "!pip install -e /content/CLIP\n",
    "!pip install  kornia==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LolgN_25qMON"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"/content/latent-diffusion\")\n",
    "sys.path.append('/content/taming-transformers')\n",
    "sys.path.append(\"/content/CLIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q61sIMCEpTFe",
    "outputId": "44a3556e-3cfa-450b-8dee-f9129c1fb96f"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6SV7Nwhh7So"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_PATH=\"/content/latent-diffusion/data/Tufts_Raw_Test\"\n",
    "if not os.path.isdir(DATA_PATH):\n",
    "  os.makedirs(DATA_PATH)\n",
    "\n",
    "!cp /content/drive/MyDrive/Tufs_Raw_Test/* /content/latent-diffusion/data/Tufts_Raw_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_4Csug_h_yR",
    "outputId": "5de51899-c654-462b-cfa5-710411792142"
   },
   "outputs": [],
   "source": [
    "%cd /content/latent-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhnCQEy_hPI-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from einops import rearrange\n",
    "\n",
    "from ldm.data.teethseg import SegmentationBase\n",
    "\n",
    "class TeethSegTest(SegmentationBase):\n",
    "    def __init__(self, size=None, random_crop=False, interpolation=\"bicubic\"):\n",
    "        super().__init__(file_path=\"/content/latent-diffusion/data/Tufts_Raw_Test\",img_dim=size,data_flip=True,with_abnormality=True,apply_flip=False)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "config_path = '/content/latent-diffusion/models/ldm/teeth/config.yaml'\n",
    "ckpt_path = '/content/drive/MyDrive/2022-11-01T19-41-14_config/checkpoints/epoch=000179.ckpt'\n",
    "\n",
    "dataset = TeethSegTest(size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drL-Qzcxloq7",
    "outputId": "73c89c92-f29d-4ae4-f281-7397077b83bd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from ldm.util import instantiate_from_config\n",
    "\n",
    "\n",
    "def load_model_from_config(config, ckpt):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt)#, map_location=\"cpu\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    config = OmegaConf.load(config_path)  \n",
    "    model = load_model_from_config(config, ckpt_path)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtAnm3uNlpx0",
    "outputId": "086126ec-db29-4806-f6a2-df2815c1471b"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "x_samples_ddim=list()\n",
    "x_reals_ddim=list()\n",
    "x_condition_ddim=list()\n",
    "for i, data in enumerate(dataloader):\n",
    "  print(i)\n",
    "  seg = data['segmentation']\n",
    "  with torch.no_grad():\n",
    "      seg = rearrange(seg, 'b h w c -> b c h w')\n",
    "      condition = model.to_rgb(seg)\n",
    "      seg = seg.to('cuda').float()\n",
    "\n",
    "     \n",
    "      seg = model.get_learned_conditioning(seg)\n",
    "      samples, _ = model.sample_log(cond=seg, batch_size=4, ddim=True,ddim_steps=200, eta=1.)\n",
    "      samples = model.decode_first_stage(samples)\n",
    "      samples = torch.clamp((samples+1.0)/2.0, min=0.0, max=1.0)\n",
    "     #samples = torch.clamp((samples+torch.abs(torch.min(samples)))/(torch.max(samples)), min=0.0, max=1.0)\n",
    "\n",
    "      samples = rearrange(samples, ' b c h w -> b h w c')\n",
    "\n",
    "      x_samples_ddim.append(samples.cpu().detach().numpy())\n",
    "      x_reals_ddim.append(data[\"image\"].cpu().detach().numpy())\n",
    "      x_condition_ddim.append(data[\"segmentation\"].cpu().detach().numpy())\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGZxNqS4NKpP"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_samples=np.asarray(x_samples_ddim)\n",
    "x_samples=np.reshape(x_samples,(100,256,256,3))\n",
    "x_reals=np.asarray(x_reals_ddim)\n",
    "x_reals=np.reshape(x_reals,(100,256,256,3))\n",
    "\n",
    "x_condition=np.asarray(x_condition_ddim)\n",
    "x_condition=np.reshape(x_condition,(100,256,256,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "iyFHurXrwyS3",
    "outputId": "514e1a56-7ab5-4858-9d2f-469fc3ec4430"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(np.uint8(x_samples[0]*255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxPP8GBZlA4G"
   },
   "outputs": [],
   "source": [
    "\n",
    "from math import log10, sqrt\n",
    "import cv2\n",
    "import numpy as np\n",
    "  \n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "\n",
    "def get_psnr(fakes,reals):\n",
    "  loss_psnr=[]\n",
    "  for i in range(len(reals)):\n",
    "    real=reals[i,:,:,:]\n",
    "    fake=fakes[i,:,:,:]\n",
    "    loss_psnr.append(PSNR(real,fake))\n",
    "  return np.asarray(loss_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aL5qDZr2HNhC"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def convert_uint8(list_imgs):\n",
    "    res_list=[]\n",
    "    for i in range(len(list_imgs)):\n",
    "      res=np.uint8(((list_imgs[i,:,:,:])*255))\n",
    "      res_list.append(res)\n",
    "    return np.asarray(res_list)\n",
    "\n",
    "\n",
    "def save_ssim(save_path,loss_ssim,name):\n",
    "      ssim=list(loss_ssim.numpy())\n",
    "      df=pd.DataFrame(data={\"ssim\":ssim})\n",
    "      path=os.path.join(save_path,\"{}_results_ssim.csv\".format(name))\n",
    "      df.to_csv(path, index=False)\n",
    "  \n",
    "def save_psnr(save_path,loss_psnr,name):\n",
    "    psnr=list(loss_psnr)\n",
    "    df=pd.DataFrame(data={\"psnr\":psnr})\n",
    "    path=os.path.join(save_path,\"{}_results_psnr.csv\".format(name))\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmTO9cDPN9nB"
   },
   "outputs": [],
   "source": [
    "t_samples=convert_uint8(x_samples)\n",
    "x_reals=(x_reals+1)/2\n",
    "t_reals=convert_uint8(x_reals)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P47tP_u4SrD0",
    "outputId": "2340c392-dadf-4a51-c302-96ad5dbc2856"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "#We use tensorflow beacuse it should be same metric with other gan models .. \n",
    "\n",
    "loss_psnr=get_psnr(t_samples, t_reals)\n",
    "loss_ssim = tf.image.ssim(t_samples, t_reals ,max_val=255, filter_size=11,\n",
    "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
    "\n",
    "save_ssim(\"/content/drive/MyDrive/LatentDiffusionResults/\",loss_ssim,\"latent_diffusion\")\n",
    "save_psnr(\"/content/drive/MyDrive/LatentDiffusionResults/\",loss_psnr,\"latent_diffusion\")\n",
    "\n",
    "print(\"Structre Similiratiy : \" ,tf.reduce_mean(loss_ssim).numpy())\n",
    "print(\"PSNR : \" ,np.mean(loss_psnr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXtHJUOGSZWc"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def threshold(categorical_map):\n",
    "    k=categorical_map[:,:,2]+categorical_map[:,:,3]+categorical_map[:,:,4]\n",
    "    k=(k>0)*1\n",
    "    return k\n",
    "def make_threshold(list_imgs,list_segs):\n",
    "    res_list=[]\n",
    "    for i in range(len(list_imgs)):\n",
    "      a=np.uint8((threshold(list_segs[i,:,:,:])*255))\n",
    "      ret, mask = cv2.threshold(a, 0, 255, cv2.THRESH_BINARY)\n",
    "      img=np.uint8((list_imgs[i,:,:,:]*255))\n",
    "      res = cv2.bitwise_and(img,img,mask = mask)\n",
    "      res_list.append(res)\n",
    "    return np.asarray(res_list)\n",
    "\n",
    "\n",
    "thresholded_samples=make_threshold(x_samples,x_condition)\n",
    "thresholded_reals=make_threshold(x_reals,x_condition)\n",
    "\n",
    "\n",
    "real_save_path=\"/content/drive/MyDrive/LatentDiffusionResults/real\"\n",
    "if not os.path.isdir(real_save_path):\n",
    "  os.makedirs(real_save_path)\n",
    "\n",
    "fake_save_path=\"/content/drive/MyDrive/LatentDiffusionResults/fake\"\n",
    "if not os.path.isdir(fake_save_path):\n",
    "  os.makedirs(fake_save_path)\n",
    "\n",
    "\n",
    "for i in range(len(t_reals)):\n",
    "   real_img=thresholded_reals[i,:,:,:]\n",
    "   fake_img=thresholded_samples[i,:,:,:]\n",
    "   fake_img=cv2.resize(fake_img, (512, 256), interpolation= cv2.INTER_LANCZOS4)\n",
    "   fake_img = cv2.fastNlMeansDenoisingColored(fake_img,None,3,3,7,5)\n",
    "   real_img=cv2.resize(real_img, (512, 256), interpolation= cv2.INTER_LANCZOS4)\n",
    "\n",
    "   cv2.imwrite(os.path.join(real_save_path,(str(i)+\"_real.png\")),real_img)\n",
    "   cv2.imwrite(os.path.join(fake_save_path,(str(i)+\"_{}fake.png\".format(\"LDM\"))),fake_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "ufDsiLxvvyxw",
    "outputId": "7d222449-5b37-4764-b90c-769b40a40c86"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(thresholded_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "6LTTo4gkv7mv",
    "outputId": "e8da4e61-31c1-406c-efab-b40cb42f16c2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(thresholded_reals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "cruERMi6veFX",
    "outputId": "73b7894c-7b8d-42fc-efc8-1329e36cbbe0"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "\n",
    "grid = rearrange(samples, ' b h w c -> b c h w')\n",
    "grid = rearrange(grid, ' b c h w -> (b) c h w')\n",
    "grid = make_grid(grid, nrow=3)\n",
    "\n",
    "# to image\n",
    "grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
    "Image.fromarray(grid.astype(np.uint8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "H8WDPK9Uv8Jf",
    "outputId": "05af0558-e1f3-4f15-fe9b-b126ec02f555"
   },
   "outputs": [],
   "source": [
    "grid2 = torch.clamp((condition+1.0)/2.0, min=0.0, max=1.0)\n",
    "grid2 = rearrange(grid2, ' b c h w -> (b) c h w')\n",
    "grid2 = make_grid(grid2, nrow=3)\n",
    "\n",
    "# to image\n",
    "grid2 = 255. * rearrange(grid2, 'c h w -> h w c').cpu().numpy()\n",
    "Image.fromarray(grid2.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "lmAaiZqvDscB",
    "outputId": "73d06a4a-dcba-40f8-ea88-b36597ad1b4c"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from einops import rearrange\n",
    "\n",
    "grid = rearrange(data[\"image\"], ' b h w c -> b c h w')\n",
    "grid = torch.clamp((grid+1.0)/2.0, min=0.0, max=1.0)\n",
    "grid = rearrange(grid, ' b c h w -> (b) c h w')\n",
    "grid = make_grid(grid, nrow=3)\n",
    "\n",
    "# to image\n",
    "grid = 255. * rearrange(grid, 'c h w -> h w c').cpu().numpy()\n",
    "Image.fromarray(grid.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFfPqvhhw-is",
    "outputId": "14308fa1-66b5-44ef-f3cd-7d2ee6bd2f89"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-tgLxInxEdW"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir /content/drive/MyDrive/VQGanTeeth/2022-10-29T10-34-42_vq_config/testtube/version_6/tf\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
